{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Setup**"
      ],
      "metadata": {
        "id": "binRR3SW6v_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download / Prepare Dataset**\n",
        "Use the Countries Flags Dataset (24 countries, ~48.5 MB).  \n",
        "The dataset is stored on Google Drive and will be downloaded and extracted into Colab, preparing it for loading and preprocessing.\n"
      ],
      "metadata": {
        "id": "rKP0YpOtivgh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQmO-Ej0dIQJ"
      },
      "outputs": [],
      "source": [
        "# Install gdown for downloading files from Google Drive\n",
        "!pip install -q gdown\n",
        "\n",
        "# Download the ZIP from Google Drive\n",
        "!gdown https://drive.google.com/uc?id=11jbRhBOS0cofCYv6HaB0IpKI8RzFk40z -O flags.zip\n",
        "\n",
        "# Unzip into 'images/' folder\n",
        "!unzip -q flags.zip -d images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Images & Labels**\n",
        "Load all flag images from the 'images/Flags' folder into memory and create corresponding labels for each image.  \n",
        "Display a sample image with its label to verify that the data has loaded correctly.\n",
        "\n"
      ],
      "metadata": {
        "id": "LeTilIG_sEI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and test the dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Functions to list directories and find all JPG images\n",
        "def list_files_in_directory(folder_path):\n",
        "    return os.listdir(folder_path)\n",
        "\n",
        "def find_jpg_paths(folder_path):\n",
        "    jpg_paths = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\"):\n",
        "                jpg_paths.append(os.path.join(root, file))\n",
        "    return jpg_paths\n",
        "\n",
        "# Load images and create labels\n",
        "flags = []\n",
        "labels = []\n",
        "\n",
        "# Folder containing country subfolders\n",
        "dataset_path = \"/content/images/Flags\"\n",
        "\n",
        "for country in list_files_in_directory(dataset_path):\n",
        "    flag_paths = find_jpg_paths(os.path.join(dataset_path, country))\n",
        "    for path in flag_paths:\n",
        "        image = Image.open(path)\n",
        "        flags.append(image)\n",
        "        labels.append(country)\n",
        "\n",
        "# Display a sample image with its label as a sanity check\n",
        "index = 146  # example index\n",
        "print(f\"Label: {labels[index]}\")\n",
        "plt.imshow(flags[index])\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d1zimhxMsFyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transform, Split, and Augment**\n",
        "Apply image transformations and AutoAugment to the training dataset, and standard transformations to the test dataset.  \n",
        "Split the dataset into training and testing sets and create DataLoaders to efficiently feed images to the model during training and testing.\n",
        "\n"
      ],
      "metadata": {
        "id": "1QnJNnmQz6oX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transforms, loading, and splitting\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import AutoAugmentPolicy\n",
        "\n",
        "def split_dataset(display=False, batch_size=8):\n",
        "    \"\"\"\n",
        "    Load the Flags dataset, apply transformations, split into train/test sets,\n",
        "    and return DataLoaders.\n",
        "\n",
        "    Args:\n",
        "        display (bool): If True, prints dataset info.\n",
        "        batch_size (int): Number of images per batch in DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        train_loader, test_loader (DataLoader): PyTorch DataLoaders for training and testing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Transformations\n",
        "    transform_no_augment = transforms.Compose([\n",
        "        transforms.Resize([224,224]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_augment = transforms.Compose([\n",
        "        transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
        "        transforms.Resize([224,224]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load dataset using ImageFolder (expects subfolders for each class)\n",
        "    dataset = ImageFolder(root='/content/images/Flags')\n",
        "\n",
        "    # Split into train/test sets (80% train, 20% test)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    # Apply transforms\n",
        "    train_dataset.dataset.transform = transform_augment\n",
        "    test_dataset.dataset.transform = transform_no_augment\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Display dataset info if requested\n",
        "    if display:\n",
        "        print(f\"Total images: {len(dataset)}\")\n",
        "        print(f\"Training set size: {len(train_dataset)}\")\n",
        "        print(f\"Testing set size: {len(test_dataset)}\")\n",
        "        print(f\"Number of classes: {len(dataset.classes)}\")\n",
        "        print(f\"Classes: {dataset.classes}\")\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# Test the function\n",
        "train_load, test_load = split_dataset(display=True)\n"
      ],
      "metadata": {
        "id": "pj1KsemWz9nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**"
      ],
      "metadata": {
        "id": "eCzuGR4s9y2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Network Architecture**\n",
        "Establish a convolutional neural network with two convolutional layers and three fully connected layers.  \n",
        "Set up the network to run on GPU if available, and verify the model output shape with a random input."
      ],
      "metadata": {
        "id": "0bpAf7c01Jfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple CNN for flag classification.\n",
        "    Input: 3x224x224 images\n",
        "    Output: 24-class flag predictions\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(16 * 54 * 54, 120)  # after conv + pool\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 24)             # 24 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 54 * 54)            # Flatten for fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Initialize model\n",
        "model = Net().to(device)\n",
        "\n",
        "# Test forward pass with random input\n",
        "inputs = torch.randn(1, 3, 224, 224).to(device)\n",
        "outputs = model(inputs)\n",
        "print(\"Output shape:\", outputs.size())\n"
      ],
      "metadata": {
        "id": "krbRmHg71J_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Function**\n",
        "Define a function to train the convolutional neural network using cross-entropy loss and stochastic gradient descent (SGD).  \n",
        "Train for a set number of epochs or until a target loss is reached, and display loss statistics after each epoch."
      ],
      "metadata": {
        "id": "HDRV0Zp4A5lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "\n",
        "def train(model: nn.Module, dataloader: DataLoader, device: torch.device):\n",
        "    \"\"\"\n",
        "    Train a convolutional neural network using cross-entropy loss and SGD.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network to train.\n",
        "        dataloader (DataLoader): DataLoader for training data.\n",
        "        device (torch.device): CPU or GPU device for training.\n",
        "\n",
        "    Training runs for up to 15 epochs or until the average loss falls below 1.\n",
        "    Loss statistics are printed after each epoch.\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    max_epochs = 15\n",
        "    target_loss = 1\n",
        "    epoch = 0\n",
        "    avg_loss = target_loss + 1\n",
        "\n",
        "    while avg_loss > target_loss and epoch < max_epochs:\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(dataloader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / (i + 1)\n",
        "        print(f\"[Epoch {epoch+1}, Batch {i+1}] Loss: {avg_loss:.5f}\")\n",
        "        epoch += 1\n",
        "\n",
        "    print(\"\\nTraining Complete\")\n",
        "    print(f\"Final Loss: {avg_loss:.5f}\")\n",
        "    print(f\"Total Epochs: {epoch}\\n\")\n"
      ],
      "metadata": {
        "id": "5yGAJ9-1-aNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing Function**\n",
        "Define a function to evaluate the trained network on a test dataset.  \n",
        "The function computes accuracy as the percentage of correctly predicted labels.  \n",
        "Optionally, limit the number of samples used for faster testing."
      ],
      "metadata": {
        "id": "RU2_iQCqCFJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate the model on a dataset and return accuracy (%).\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained neural network.\n",
        "        dataloader (DataLoader): DataLoader for test data.\n",
        "        max_samples (int, optional): Max number of samples to evaluate. Default is all.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy in percentage.\n",
        "    \"\"\"\n",
        "    correct, total, n_inferences = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if max_samples:\n",
        "                n_inferences += images.size(0)\n",
        "                if n_inferences > max_samples:\n",
        "                    break\n",
        "\n",
        "    return 100 * correct / total\n"
      ],
      "metadata": {
        "id": "-EyrjY4pCFcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Full Training & Testing**\n",
        "Resplit the dataset, reinitialize the network, and run training followed by evaluation.  \n",
        "Prints the final test accuracy of the model."
      ],
      "metadata": {
        "id": "iJmuJECvD7xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Run a full training and evaluation cycle.\n",
        "\n",
        "- Resplits the dataset for a fresh run.\n",
        "- Reinitializes the network.\n",
        "- Trains the network using `train()`.\n",
        "- Evaluates the network using `test()` and prints final accuracy.\n",
        "\"\"\"\n",
        "\n",
        "# Re-split dataset and reinitialize model\n",
        "train_load, test_load = split_dataset()  # Resplit data each time\n",
        "model = Net().to(device)                  # Re-establish a new network\n",
        "\n",
        "# Train the model\n",
        "train(model, train_load, device)\n",
        "\n",
        "# Evaluate the model\n",
        "score = test(model, test_load)\n",
        "print(f'Accuracy of the network on the test images: {score:.2f}%')"
      ],
      "metadata": {
        "id": "ipr7PhHlD8bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate on Different Hardware**"
      ],
      "metadata": {
        "id": "y5oZddcCL9u1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Test Images**"
      ],
      "metadata": {
        "id": "M82XoyFIURMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fvcore\n",
        "import time\n",
        "import psutil\n",
        "import subprocess\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "import logging\n",
        "logging.getLogger(\"fvcore.nn.jit_analysis\").setLevel(logging.ERROR)\n",
        "\n",
        "# Download images from Google Drive\n",
        "!gdown https://drive.google.com/uc?id=1jqWHMlXisqgsYqSO5oy2VcpGY3hS6iyQ -O /content/Italy_Flag.png"
      ],
      "metadata": {
        "id": "j6GBFZsoSevl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CPU Testing**\n",
        "Test the trained network on a CPU to verify functionality and measure performance.  \n",
        "This allows comparison with GPU results and ensures the model runs on systems without a GPU."
      ],
      "metadata": {
        "id": "3HPrW8jrL-SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Force device to CPU\n",
        "device = torch.device(\"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Re-initialize model on CPU\n",
        "model = Net().to(device)\n",
        "model.eval()  # Evaluation mode (no dropout, batchnorm frozen, etc.)\n",
        "\n",
        "# Path to test image (upload or place in /content/)\n",
        "test_image_path = '/content/Italy_Flag.png'  # <-- Change if using a different image\n",
        "image = Image.open(test_image_path)\n",
        "\n",
        "# Apply same preprocessing as training\n",
        "auto_augment_policy = AutoAugmentPolicy.IMAGENET\n",
        "transform = transforms.Compose([\n",
        "    transforms.AutoAugment(policy=auto_augment_policy),\n",
        "    transforms.Resize([224, 224]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transform + add batch dimension\n",
        "image = transform(image).unsqueeze(0).to(device)  # shape: [1, 3, 224, 224]\n",
        "\n",
        "# Compute FLOPs (per forward pass)\n",
        "flop = FlopCountAnalysis(model, image)\n",
        "total_flops = flop.total()\n",
        "\n",
        "# Run inference multiple times to benchmark runtime\n",
        "number_of_runs = 1000  # Reduced from 10000 to keep runtime practical\n",
        "time_before = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(number_of_runs):\n",
        "        outputs = model(image)\n",
        "time_after = time.time()\n",
        "\n",
        "# Runtime results\n",
        "total_time = time_after - time_before\n",
        "gops = (total_flops * number_of_runs / 1e9) / total_time  # GOPs/sec\n",
        "\n",
        "# CPU utilization snapshot (not exact science, just context)\n",
        "cpu_usage = psutil.cpu_percent(interval=1)\n",
        "\n",
        "# Display results\n",
        "print(f\"Runtime: {total_time:.2f} s\")\n",
        "print(f\"GOPs/sec: {gops:.2f}\")\n",
        "print(f\"CPU Usage: {cpu_usage}%\")\n"
      ],
      "metadata": {
        "id": "d_dIToejL_xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GPU Testing**\n",
        "Test the trained network on a GPU to measure improved performance and training speed.  \n",
        "This highlights the efficiency gains from hardware acceleration compared to CPU execution."
      ],
      "metadata": {
        "id": "97oZYzv6MB9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Re-initialize model on GPU\n",
        "model = Net().to(device)\n",
        "model.eval()  # Evaluation mode disables dropout, batchnorm updates, etc.\n",
        "\n",
        "# Path to test image (upload or place in /content/)\n",
        "test_image_path = '/content/Italy_Flag.png'  # <-- Change if using a different image\n",
        "image = Image.open(test_image_path)\n",
        "\n",
        "# Apply same preprocessing as training\n",
        "auto_augment_policy = AutoAugmentPolicy.IMAGENET\n",
        "transform = transforms.Compose([\n",
        "    transforms.AutoAugment(policy=auto_augment_policy),\n",
        "    transforms.Resize([224, 224]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transform + add batch dimension for inference\n",
        "image = transform(image).unsqueeze(0).to(device)  # shape: [1, 3, 224, 224]\n",
        "\n",
        "# Compute FLOPs (per forward pass)\n",
        "flop = FlopCountAnalysis(model, image)\n",
        "total_flops = flop.total()\n",
        "\n",
        "# Run inference multiple times to benchmark runtime\n",
        "number_of_runs = 1000  # adjust for longer/shorter test\n",
        "time_before = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(number_of_runs):\n",
        "        outputs = model(image)\n",
        "time_after = time.time()\n",
        "\n",
        "# Runtime results\n",
        "total_time = time_after - time_before\n",
        "gops = (total_flops * number_of_runs / 1e9) / total_time  # GOPs/sec\n",
        "\n",
        "# Query GPU utilization (%)\n",
        "gpu_process = subprocess.Popen(\n",
        "    ['nvidia-smi',\n",
        "     '--query-gpu=utilization.gpu',\n",
        "     '--format=csv,noheader,nounits'],\n",
        "    stdout=subprocess.PIPE\n",
        ")\n",
        "gpu_output, _ = gpu_process.communicate()\n",
        "gpu_usage = float(gpu_output.strip())\n",
        "\n",
        "# Helper function to grab extra GPU stats\n",
        "def get_gpu_info():\n",
        "    result = subprocess.run(\n",
        "        ['nvidia-smi',\n",
        "         '--query-gpu=name,memory.total,memory.used,memory.free,temperature.gpu,power.draw',\n",
        "         '--format=csv,noheader,nounits'],\n",
        "        stdout=subprocess.PIPE\n",
        "    )\n",
        "    output = result.stdout.decode('utf-8').strip().split('\\n')\n",
        "    gpu_info = []\n",
        "    for line in output:\n",
        "        info = line.split(', ')\n",
        "        gpu_info.append({\n",
        "            'GPU Name': info[0],\n",
        "            'Memory (Total MB)': int(info[1]),\n",
        "            'Memory (Used MB)': int(info[2]),\n",
        "            'Memory (Free MB)': int(info[3]),\n",
        "            'Temperature (C)': int(info[4]),\n",
        "            'Power Draw (W)': float(info[5])\n",
        "        })\n",
        "    return gpu_info\n",
        "\n",
        "gpu_info = get_gpu_info()\n",
        "power_usage = total_time * gpu_info[0]['Power Draw (W)']  # Joules = W * s\n",
        "\n",
        "# Display results\n",
        "print(f\"Runtime: {total_time:.2f} s\")\n",
        "print(f\"GOPs/sec: {gops:.2f}\")\n",
        "print(f\"GPU Usage: {gpu_usage}%\")\n",
        "print(f\"Power Usage Estimate: {power_usage:.2f} J\")\n",
        "print(\"GPU Info:\", gpu_info[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "e1K4cteANE0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}